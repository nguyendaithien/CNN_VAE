
****** Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2019.2 (64-bit)
  **** SW Build 2708876 on Wed Nov  6 21:39:14 MST 2019
  **** IP Build 2700528 on Thu Nov  7 00:09:20 MST 2019
    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.

source /tools/Xilinxs/Vitis/2019.2/scripts/vitis_hls/hls.tcl -notrace
INFO: [HLS 200-10] Running '/tools/Xilinxs/Vitis/2019.2/bin/unwrapped/lnx64.o/vitis_hls'
INFO: [HLS 200-10] For user 'snn' on host 'snn-HP-280-Pro-G8-Microtower-PC' (Linux_x86_64 version 5.15.0-92-generic) on Mon Jan 29 21:00:41 +07 2024
INFO: [HLS 200-10] On os Ubuntu 20.04.6 LTS
INFO: [HLS 200-10] In directory '/home/snn/CNN_VAE/CNN_VAE/test_serial'
Sourcing Tcl script 'run_hls.tcl'
INFO: [HLS 200-10] Opening and resetting project '/home/snn/CNN_VAE/CNN_VAE/test_serial/line_buffer_code_C'.
INFO: [HLS 200-10] Adding design file 'model.cpp' to the project
INFO: [HLS 200-10] Adding test bench file 'test.cpp' to the project
INFO: [HLS 200-10] Opening and resetting solution '/home/snn/CNN_VAE/CNN_VAE/test_serial/line_buffer_code_C/solution1'.
INFO: [HLS 200-10] Cleaning up the solution database.
INFO: [HLS 200-10] Setting target device to 'xcvu9p-flga2104-2-i'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 6.66ns.
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
   Compiling ../../../../test.cpp in debug mode
   Compiling ../../../../model.cpp in debug mode
   Generating csim.exe
 0.31635 0.579084 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.603288 0.375447
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.438105 0.769222 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.879655 0.7579 0.461676
        0.234248 0.311399 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.5287 0.406946 0.0914687
        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
       INFO: [SIM 211-1] CSim done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
INFO: [HLS 200-10] Analyzing design file 'model.cpp' ... 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' target.
INFO: [HLS 214-131] Inlining function 'relu(double)' into 'void convolution<double, double, double, double, 28, 28, 1, 16, 28, 28, 3, 3, 1, 1>(int, int, int, double*, double*, double const*, double*)' (./CNN.h:88:119)
INFO: [HLS 214-131] Inlining function 'relu(double)' into 'void convolution<double, double, double, double, 14, 14, 16, 8, 14, 14, 3, 3, 1, 1>(int, int, int, double*, double*, double const*, double*)' (./CNN.h:88:119)
INFO: [HLS 214-131] Inlining function 'relu(double)' into 'void convolution<double, double, double, double, 7, 7, 8, 8, 7, 7, 3, 3, 1, 1>(int, int, int, double*, double*, double const*, double*)' (./CNN.h:88:119)
INFO: [HLS 214-131] Inlining function 'relu(double)' into 'void convolution<double, double, double, double, 4, 4, 8, 8, 4, 4, 3, 3, 1, 1>(int, int, int, double*, double*, double const*, double*)' (./CNN.h:88:119)
INFO: [HLS 214-131] Inlining function 'relu(double)' into 'void convolution<double, double, double, double, 8, 8, 8, 8, 8, 8, 3, 3, 1, 1>(int, int, int, double*, double*, double const*, double*)' (./CNN.h:88:119)
INFO: [HLS 214-131] Inlining function 'relu(double)' into 'void convolution<double, double, double, double, 16, 16, 8, 16, 14, 14, 3, 3, 1, 0>(int, int, int, double*, double*, double const*, double*)' (./CNN.h:88:119)
INFO: [HLS 214-131] Inlining function 'relu(double)' into 'void convolution<double, double, double, double, 28, 28, 16, 1, 28, 28, 3, 3, 1, 0>(int, int, int, double*, double*, double const*, double*)' (./CNN.h:88:119)
INFO: [HLS 214-131] Inlining function 'void max_pooling<double, double, 16, 28, 28, 14, 14, 2, 1>(int, int, double*, double*)' into 'CNN(int, int, int, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*)' (model.cpp:24:1)
INFO: [HLS 214-131] Inlining function 'void max_pooling<double, double, 8, 14, 14, 7, 7, 2, 1>(int, int, double*, double*)' into 'CNN(int, int, int, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*)' (model.cpp:26:1)
INFO: [HLS 214-131] Inlining function 'void upsampling<double, double, 14, 14, 16, 28, 28, 2, 2>(int, int, double*, double*)' into 'CNN(int, int, int, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*)' (model.cpp:34:1)
INFO: [HLS 214-131] Inlining function 'void max_pooling<double, double, 8, 7, 7, 4, 4, 2, 1>(int, int, double*, double*)' into 'CNN(int, int, int, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*)' (model.cpp:28:1)
INFO: [HLS 214-131] Inlining function 'void upsampling<double, double, 8, 8, 8, 16, 16, 2, 2>(int, int, double*, double*)' into 'CNN(int, int, int, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*)' (model.cpp:32:1)
INFO: [HLS 214-131] Inlining function 'void upsampling<double, double, 8, 4, 4, 8, 8, 2, 2>(int, int, double*, double*)' into 'CNN(int, int, int, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*)' (model.cpp:30:1)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:57:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:58:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:59:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:60:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:61:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:62:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:57:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:58:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:59:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:60:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:61:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:62:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:57:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:58:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:59:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:60:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:61:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:62:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:57:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:58:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:59:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:60:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:61:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:62:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:57:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:58:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:59:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:60:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:61:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:62:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:57:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:58:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:59:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:60:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:61:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:62:31)
WARNING: [HLS 214-167] The program may have out of bound array access
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:57:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:58:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:59:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:60:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:61:31)
WARNING: [HLS 214-167] The program may have out of bound array access (./CNN.h:62:31)
WARNING: [HLS 200-651] Found issues in source files:
warning: ./CNN.h:57:31: The program may have out of bound array access
warning: ./CNN.h:58:31: The program may have out of bound array access
warning: ./CNN.h:59:31: The program may have out of bound array access
warning: ./CNN.h:60:31: The program may have out of bound array access
warning: ./CNN.h:61:31: The program may have out of bound array access
warning: ./CNN.h:62:31: The program may have out of bound array access
warning: ./CNN.h:57:31: The program may have out of bound array access
warning: ./CNN.h:58:31: The program may have out of bound array access
warning: ./CNN.h:59:31: The program may have out of bound array access
warning: ./CNN.h:60:31: The program may have out of bound array access
warning: ./CNN.h:61:31: The program may have out of bound array access
warning: ./CNN.h:62:31: The program may have out of bound array access
warning: ./CNN.h:57:31: The program may have out of bound array access
warning: ./CNN.h:58:31: The program may have out of bound array access
warning: ./CNN.h:59:31: The program may have out of bound array access
warning: ./CNN.h:60:31: The program may have out of bound array access
warning: ./CNN.h:61:31: The program may have out of bound array access
warning: ./CNN.h:62:31: The program may have out of bound array access
warning: ./CNN.h:57:31: The program may have out of bound array access
warning: ./CNN.h:58:31: The program may have out of bound array access
warning: ./CNN.h:59:31: The program may have out of bound array access
warning: ./CNN.h:60:31: The program may have out of bound array access
warning: ./CNN.h:61:31: The program may have out of bound array access
warning: ./CNN.h:62:31: The program may have out of bound array access
warning: ./CNN.h:57:31: The program may have out of bound array access
warning: ./CNN.h:58:31: The program may have out of bound array access
warning: ./CNN.h:59:31: The program may have out of bound array access
warning: ./CNN.h:60:31: The program may have out of bound array access
warning: ./CNN.h:61:31: The program may have out of bound array access
warning: ./CNN.h:62:31: The program may have out of bound array access
warning: ./CNN.h:57:31: The program may have out of bound array access
warning: ./CNN.h:58:31: The program may have out of bound array access
warning: ./CNN.h:59:31: The program may have out of bound array access
warning: ./CNN.h:60:31: The program may have out of bound array access
warning: ./CNN.h:61:31: The program may have out of bound array access
warning: ./CNN.h:62:31: The program may have out of bound array access
warning: <unknown>:0:0: The program may have out of bound array access
warning: ./CNN.h:57:31: The program may have out of bound array access
warning: ./CNN.h:58:31: The program may have out of bound array access
warning: ./CNN.h:59:31: The program may have out of bound array access
warning: ./CNN.h:60:31: The program may have out of bound array access
warning: ./CNN.h:61:31: The program may have out of bound array access
warning: ./CNN.h:62:31: The program may have out of bound array access

INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:18 ; elapsed = 00:00:39 . Memory (MB): peak = 893.656 ; gain = 522.949 ; free physical = 3406 ; free virtual = 30576
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:18 ; elapsed = 00:00:39 . Memory (MB): peak = 893.656 ; gain = 522.949 ; free physical = 3406 ; free virtual = 30576
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:18 ; elapsed = 00:00:39 . Memory (MB): peak = 893.656 ; gain = 522.949 ; free physical = 3381 ; free virtual = 30573
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:18 ; elapsed = 00:00:39 . Memory (MB): peak = 893.656 ; gain = 522.949 ; free physical = 3379 ; free virtual = 30571
INFO: [XFORM 203-510] Pipelining loop 'Loop-2.1.1.1' (./CNN.h:42) in function 'convolution<double, double, double, double, 14, 14, 16, 8, 14, 14, 3, 3, 1, 1>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 14, 14, 16, 8, 14, 14, 3, 3, 1, 1>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2.1.1.1' (./CNN.h:42) in function 'convolution<double, double, double, double, 16, 16, 8, 16, 14, 14, 3, 3, 1, 0>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 16, 16, 8, 16, 14, 14, 3, 3, 1, 0>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2.1.1' (./CNN.h:42) in function 'convolution<double, double, double, double, 28, 28, 1, 16, 28, 28, 3, 3, 1, 1>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 28, 28, 1, 16, 28, 28, 3, 3, 1, 1>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2.1.1' (./CNN.h:42) in function 'convolution<double, double, double, double, 28, 28, 16, 1, 28, 28, 3, 3, 1, 0>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 28, 28, 16, 1, 28, 28, 3, 3, 1, 0>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2.1.1.1' (./CNN.h:42) in function 'convolution<double, double, double, double, 4, 4, 8, 8, 4, 4, 3, 3, 1, 1>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 4, 4, 8, 8, 4, 4, 3, 3, 1, 1>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2.1.1.1' (./CNN.h:42) in function 'convolution<double, double, double, double, 7, 7, 8, 8, 7, 7, 3, 3, 1, 1>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 7, 7, 8, 8, 7, 7, 3, 3, 1, 1>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2.1.1.1' (./CNN.h:42) in function 'convolution<double, double, double, double, 8, 8, 8, 8, 8, 8, 3, 3, 1, 1>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 8, 8, 8, 8, 8, 8, 3, 3, 1, 1>' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-2.1.1' (./CNN.h:117) in function 'CNN' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-3.1.1' (./CNN.h:117) in function 'CNN' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-4.1.1' (./CNN.h:117) in function 'CNN' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-5.1.1' (./CNN.h:150) in function 'CNN' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-6.1.1' (./CNN.h:150) in function 'CNN' automatically.
INFO: [XFORM 203-510] Pipelining loop 'Loop-7.1.1' (./CNN.h:150) in function 'CNN' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 8, 8, 8, 8, 8, 8, 3, 3, 1, 1>' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 7, 7, 8, 8, 7, 7, 3, 3, 1, 1>' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 4, 4, 8, 8, 4, 4, 3, 3, 1, 1>' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 28, 28, 16, 1, 28, 28, 3, 3, 1, 0>' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 28, 28, 1, 16, 28, 28, 3, 3, 1, 1>' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 16, 16, 8, 16, 14, 14, 3, 3, 1, 0>' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Shift_win_right' (./CNN.h:65) in function 'convolution<double, double, double, double, 14, 14, 16, 8, 14, 14, 3, 3, 1, 1>' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Loop-1.1.1' (./CNN.h:117) in function 'CNN' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Loop-2.1.1' (./CNN.h:117) in function 'CNN' for pipelining.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Loop-3.1.1' (./CNN.h:117) in function 'CNN' for pipelining.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.1' (./CNN.h:65) in function 'convolution<double, double, double, double, 8, 8, 8, 8, 8, 8, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.2' (./CNN.h:81) in function 'convolution<double, double, double, double, 8, 8, 8, 8, 8, 8, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.2.1' (./CNN.h:82) in function 'convolution<double, double, double, double, 8, 8, 8, 8, 8, 8, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.1' (./CNN.h:65) in function 'convolution<double, double, double, double, 7, 7, 8, 8, 7, 7, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.2' (./CNN.h:81) in function 'convolution<double, double, double, double, 7, 7, 8, 8, 7, 7, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.2.1' (./CNN.h:82) in function 'convolution<double, double, double, double, 7, 7, 8, 8, 7, 7, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.1' (./CNN.h:65) in function 'convolution<double, double, double, double, 4, 4, 8, 8, 4, 4, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.2' (./CNN.h:81) in function 'convolution<double, double, double, double, 4, 4, 8, 8, 4, 4, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.2.1' (./CNN.h:82) in function 'convolution<double, double, double, double, 4, 4, 8, 8, 4, 4, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2.1' (./CNN.h:65) in function 'convolution<double, double, double, double, 28, 28, 16, 1, 28, 28, 3, 3, 1, 0>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2.2' (./CNN.h:81) in function 'convolution<double, double, double, double, 28, 28, 16, 1, 28, 28, 3, 3, 1, 0>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2.2.1' (./CNN.h:82) in function 'convolution<double, double, double, double, 28, 28, 16, 1, 28, 28, 3, 3, 1, 0>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2.1' (./CNN.h:65) in function 'convolution<double, double, double, double, 28, 28, 1, 16, 28, 28, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2.2' (./CNN.h:81) in function 'convolution<double, double, double, double, 28, 28, 1, 16, 28, 28, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2.2.1' (./CNN.h:82) in function 'convolution<double, double, double, double, 28, 28, 1, 16, 28, 28, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.1' (./CNN.h:65) in function 'convolution<double, double, double, double, 16, 16, 8, 16, 14, 14, 3, 3, 1, 0>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.2' (./CNN.h:81) in function 'convolution<double, double, double, double, 16, 16, 8, 16, 14, 14, 3, 3, 1, 0>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.2.1' (./CNN.h:82) in function 'convolution<double, double, double, double, 16, 16, 8, 16, 14, 14, 3, 3, 1, 0>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.1' (./CNN.h:65) in function 'convolution<double, double, double, double, 14, 14, 16, 8, 14, 14, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.2' (./CNN.h:81) in function 'convolution<double, double, double, double, 14, 14, 16, 8, 14, 14, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.2.1' (./CNN.h:82) in function 'convolution<double, double, double, double, 14, 14, 16, 8, 14, 14, 3, 3, 1, 1>' completely with a factor of 3.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.1' (./CNN.h:118) in function 'CNN' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2' (./CNN.h:125) in function 'CNN' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1.2.1' (./CNN.h:126) in function 'CNN' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1.1.1' (./CNN.h:118) in function 'CNN' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1.1.2' (./CNN.h:125) in function 'CNN' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1.1.2.1' (./CNN.h:126) in function 'CNN' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Loop-3.1.1.1' (./CNN.h:118) in function 'CNN' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Loop-3.1.1.2' (./CNN.h:125) in function 'CNN' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'Loop-3.1.1.2.1' (./CNN.h:126) in function 'CNN' completely with a factor of 2.
INFO: [XFORM 203-102] Partitioning array 'window_buffer' (./CNN.h:33) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.0' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.1' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.2' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer' (./CNN.h:33) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.0' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.1' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.2' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer' (./CNN.h:33) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.0' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.1' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.2' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer' (./CNN.h:33) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.0' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.1' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.2' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer' (./CNN.h:33) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.0' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.1' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.2' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer' (./CNN.h:33) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.0' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.1' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.2' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer' (./CNN.h:33) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.0' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.1' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'window_buffer.2' (./CNN.h:33) automatically.
INFO: [XFORM 203-102] Partitioning array 'line_buffer_0' (./CNN.h:111) automatically.
INFO: [XFORM 203-102] Partitioning array 'line_buffer_1' (./CNN.h:112) automatically.
INFO: [XFORM 203-102] Partitioning array 'line_buffer_0.7' (./CNN.h:111) automatically.
INFO: [XFORM 203-102] Partitioning array 'line_buffer_1.7' (./CNN.h:112) automatically.
INFO: [XFORM 203-102] Partitioning array 'line_buffer_0.8' (./CNN.h:111) automatically.
INFO: [XFORM 203-102] Partitioning array 'line_buffer_1.8' (./CNN.h:112) automatically.
INFO: [XFORM 203-102] Automatically partitioning small array 'line_buffer_2.10' completely based on array size.
INFO: [XFORM 203-102] Automatically partitioning small array 'line_buffer_1.10' completely based on array size.
INFO: [XFORM 203-102] Automatically partitioning small array 'line_buffer_0.10' completely based on array size.
INFO: [XFORM 203-101] Partitioning array 'line_buffer_2.10' in dimension 1 completely.
INFO: [XFORM 203-101] Partitioning array 'line_buffer_1.10' in dimension 1 completely.
INFO: [XFORM 203-101] Partitioning array 'line_buffer_0.10' in dimension 1 completely.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (./CNN.h:42:14) in function 'convolution<double, double, double, double, 8, 8, 8, 8, 8, 8, 3, 3, 1, 1>'... converting 4 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (./CNN.h:42:14) in function 'convolution<double, double, double, double, 7, 7, 8, 8, 7, 7, 3, 3, 1, 1>'... converting 4 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (./CNN.h:45:18) to (./CNN.h:49:24) in function 'convolution<double, double, double, double, 4, 4, 8, 8, 4, 4, 3, 3, 1, 1>'... converting 4 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (./CNN.h:42:14) in function 'convolution<double, double, double, double, 28, 28, 16, 1, 28, 28, 3, 3, 1, 0>'... converting 4 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (./CNN.h:42:14) in function 'convolution<double, double, double, double, 28, 28, 1, 16, 28, 28, 3, 3, 1, 1>'... converting 4 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (./CNN.h:42:14) in function 'convolution<double, double, double, double, 16, 16, 8, 16, 14, 14, 3, 3, 1, 0>'... converting 4 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (./CNN.h:42:14) in function 'convolution<double, double, double, double, 14, 14, 16, 8, 14, 14, 3, 3, 1, 1>'... converting 4 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'convolution<double, double, double, double, 8, 8, 8, 8, 8, 8, 3, 3, 1, 1>' (./CNN.h:11:51)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'convolution<double, double, double, double, 7, 7, 8, 8, 7, 7, 3, 3, 1, 1>' (./CNN.h:11:51)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'convolution<double, double, double, double, 4, 4, 8, 8, 4, 4, 3, 3, 1, 1>' (./CNN.h:11:34)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'convolution<double, double, double, double, 28, 28, 16, 1, 28, 28, 3, 3, 1, 0>' (./CNN.h:11:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'convolution<double, double, double, double, 28, 28, 1, 16, 28, 28, 3, 3, 1, 1>' (./CNN.h:11:51)...3 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'convolution<double, double, double, double, 16, 16, 8, 16, 14, 14, 3, 3, 1, 0>' (./CNN.h:11:51)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'convolution<double, double, double, double, 14, 14, 16, 8, 14, 14, 3, 3, 1, 1>' (./CNN.h:11:51)...6 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:19 ; elapsed = 00:00:40 . Memory (MB): peak = 893.656 ; gain = 522.949 ; free physical = 3318 ; free virtual = 30522
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Push_pixel' (./CNN.h:42:14) in function 'convolution<double, double, double, double, 8, 8, 8, 8, 8, 8, 3, 3, 1, 1>' : 

more than one sub loop.
INFO: [XFORM 203-541] Flattening a loop nest 'Loop-1.1' (./CNN.h:40:7) in function 'convolution<double, double, double, double, 8, 8, 8, 8, 8, 8, 3, 3, 1, 1>'.
INFO: [XFORM 203-541] Flattening a loop nest 'Loop-1' (./CNN.h:39:2) in function 'convolution<double, double, double, double, 8, 8, 8, 8, 8, 8, 3, 3, 1, 1>'.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Push_pixel' (./CNN.h:42:14) in function 'convolution<double, double, double, double, 7, 7, 8, 8, 7, 7, 3, 3, 1, 1>' : 

more than one sub loop.
INFO: [XFORM 203-541] Flattening a loop nest 'Loop-1.1' (./CNN.h:40:7) in function 'convolution<double, double, double, double, 7, 7, 8, 8, 7, 7, 3, 3, 1, 1>'.
INFO: [XFORM 203-541] Flattening a loop nest 'Loop-1' (./CNN.h:39:2) in function 'convolution<double, double, double, double, 7, 7, 8, 8, 7, 7, 3, 3, 1, 1>'.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Push_pixel' (./CNN.h:42:14) in function 'convolution<double, double, double, double, 4, 4, 8, 8, 4, 4, 3, 3, 1, 1>' : 

more than one sub loop.
INFO: [XFORM 203-541] Flattening a loop nest 'Loop-1.1' (./CNN.h:40:7) in function 'convolution<double, double, double, double, 4, 4, 8, 8, 4, 4, 3, 3, 1, 1>'.
INFO: [XFORM 203-541] Flattening a loop nest 'Loop-1' (./CNN.h:39:2) in function 'convolution<double, double, double, double, 4, 4, 8, 8, 4, 4, 3, 3, 1, 1>'.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Push_pixel' (./CNN.h:42:14) in function 'convolution<double, double, double, double, 28, 28, 16, 1, 28, 28, 3, 3, 1, 0>' : 

more than one sub loop.
INFO: [XFORM 203-541] Flattening a loop nest 'Loop-1' (./CNN.h:39:2) in function 'convolution<double, double, double, double, 28, 28, 16, 1, 28, 28, 3, 3, 1, 0>'.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Push_pixel' (./CNN.h:42:14) in function 'convolution<double, double, double, double, 28, 28, 1, 16, 28, 28, 3, 3, 1, 1>' : 

more than one sub loop.
INFO: [XFORM 203-541] Flattening a loop nest 'Loop-1' (./CNN.h:40:7) in function 'convolution<double, double, double, double, 28, 28, 1, 16, 28, 28, 3, 3, 1, 1>'.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Push_pixel' (./CNN.h:42:14) in function 'convolution<double, double, double, double, 16, 16, 8, 16, 14, 14, 3, 3, 1, 0>' : 

more than one sub loop.
INFO: [XFORM 203-541] Flattening a loop nest 'Loop-1.1' (./CNN.h:40:7) in function 'convolution<double, double, double, double, 16, 16, 8, 16, 14, 14, 3, 3, 1, 0>'.
INFO: [XFORM 203-541] Flattening a loop nest 'Loop-1' (./CNN.h:39:2) in function 'convolution<double, double, double, double, 16, 16, 8, 16, 14, 14, 3, 3, 1, 0>'.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Push_pixel' (./CNN.h:42:14) in function 'convolution<double, double, double, double, 14, 14, 16, 8, 14, 14, 3, 3, 1, 1>' : 

more than one sub loop.
INFO: [XFORM 203-541] Flattening a loop nest 'Loop-1.1' (./CNN.h:40:7) in function 'convolution<double, double, double, double, 14, 14, 16, 8, 14, 14, 3, 3, 1, 1>'.
INFO: [XFORM 203-541] Flattening a loop nest 'Loop-1' (./CNN.h:39:2) in function 'convolution<double, double, double, double, 14, 14, 16, 8, 14, 14, 3, 3, 1, 1>'.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Loop-1.1' (./CNN.h:116:9) in function 'CNN' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Loop-1' (./CNN.h:115:5) in function 'CNN' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Loop-2.1' (./CNN.h:116:9) in function 'CNN' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Loop-2' (./CNN.h:115:5) in function 'CNN' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Loop-3.1' (./CNN.h:116:9) in function 'CNN' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Loop-3' (./CNN.h:115:5) in function 'CNN' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Loop-4.1' (./CNN.h:149:9) in function 'CNN' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Loop-4' (./CNN.h:148:5) in function 'CNN' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Loop-5.1' (./CNN.h:149:9) in function 'CNN' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Loop-5' (./CNN.h:148:5) in function 'CNN' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Loop-6.1' (./CNN.h:149:9) in function 'CNN' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'Loop-6' (./CNN.h:148:5) in function 'CNN' : 

the outer loop is not a perfect loop because there is nontrivial logic before entering the inner loop.
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_0' (./CNN.h:43:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_1' (./CNN.h:44:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_2' (./CNN.h:49:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_0.5' (./CNN.h:43:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_1.5' (./CNN.h:44:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_2.5' (./CNN.h:49:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_0.9' (./CNN.h:43:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_1.9' (./CNN.h:44:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_2.9' (./CNN.h:49:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_0.8' (./CNN.h:43:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_1.8' (./CNN.h:44:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_2.8' (./CNN.h:49:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_0.7' (./CNN.h:43:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_1.7' (./CNN.h:44:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_2.7' (./CNN.h:49:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_0.6' (./CNN.h:43:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_1.6' (./CNN.h:44:24)
INFO: [HLS 200-472] Inferring partial write operation for 'line_buffer_2.6' (./CNN.h:49:24)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:20 ; elapsed = 00:00:41 . Memory (MB): peak = 893.656 ; gain = 522.949 ; free physical = 3255 ; free virtual = 30459
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'CNN' ...
WARNING: [SYN 201-103] Legalizing function name 'convolution<double, double, double, double, 28, 28, 1, 16, 28, 28, 3, 3, 1, 1>' to 'convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s'.
WARNING: [SYN 201-103] Legalizing function name 'convolution<double, double, double, double, 14, 14, 16, 8, 14, 14, 3, 3, 1, 1>' to 'convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s'.
WARNING: [SYN 201-103] Legalizing function name 'convolution<double, double, double, double, 7, 7, 8, 8, 7, 7, 3, 3, 1, 1>' to 'convolution_double_double_double_double_7_7_8_8_7_7_3_3_1_1_s'.
WARNING: [SYN 201-103] Legalizing function name 'convolution<double, double, double, double, 4, 4, 8, 8, 4, 4, 3, 3, 1, 1>' to 'convolution_double_double_double_double_4_4_8_8_4_4_3_3_1_1_s'.
WARNING: [SYN 201-103] Legalizing function name 'convolution<double, double, double, double, 8, 8, 8, 8, 8, 8, 3, 3, 1, 1>' to 'convolution_double_double_double_double_8_8_8_8_8_8_3_3_1_1_s'.
WARNING: [SYN 201-103] Legalizing function name 'convolution<double, double, double, double, 16, 16, 8, 16, 14, 14, 3, 3, 1, 0>' to 'convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s'.
WARNING: [SYN 201-103] Legalizing function name 'convolution<double, double, double, double, 28, 28, 16, 1, 28, 28, 3, 3, 1, 0>' to 'convolution_double_double_double_double_28_28_16_1_28_28_3_3_1_0_s'.
WARNING: [SYN 201-107] Renaming port name 'CNN/image' to 'CNN/image_r' to avoid the conflict with HDL keywords or other object names.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'L_Push_pixel.1'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.
INFO: [SCHED 204-61] Pipelining loop 'Shift_win_right'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 47.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 41.78 seconds; current allocated memory: 230.775 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 231.741 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'L_L_Push_pixel.1'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.
INFO: [SCHED 204-61] Pipelining loop 'Shift_win_right'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 47.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 232.406 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 233.493 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'convolution_double_double_double_double_7_7_8_8_7_7_3_3_1_1_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'L_L_Push_pixel.1'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.
INFO: [SCHED 204-61] Pipelining loop 'Shift_win_right'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 47.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 234.123 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 235.201 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'convolution_double_double_double_double_4_4_8_8_4_4_3_3_1_1_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'L_L_Push_pixel.1'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'Shift_win_right'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 46.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.25 seconds; current allocated memory: 235.877 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 237.027 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'convolution_double_double_double_double_8_8_8_8_8_8_3_3_1_1_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'L_L_Push_pixel.1'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.
INFO: [SCHED 204-61] Pipelining loop 'Shift_win_right'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 47.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 237.661 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 238.737 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'L_L_Push_pixel.1'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.
INFO: [SCHED 204-61] Pipelining loop 'Shift_win_right'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 47.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.25 seconds; current allocated memory: 239.384 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 240.485 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'convolution_double_double_double_double_28_28_16_1_28_28_3_3_1_0_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'L_Push_pixel.1'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.
INFO: [SCHED 204-61] Pipelining loop 'Shift_win_right'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 47.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 241.036 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 241.984 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'CNN' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'Loop 1.1.1'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.
INFO: [SCHED 204-61] Pipelining loop 'Loop 2.1.1'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.
INFO: [SCHED 204-61] Pipelining loop 'Loop 3.1.1'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.
INFO: [SCHED 204-61] Pipelining loop 'Loop 4.1.1'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'Loop 5.1.1'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-61] Pipelining loop 'Loop 6.1.1'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 242.845 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.96 seconds; current allocated memory: 244.154 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s_line_buffer_1_2' to 'convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s_line_buffebkb' due to the length limit 80
INFO: [SYN 201-210] Renamed object name 'convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s_line_buffer_0_2' to 'convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s_line_buffecud' due to the length limit 80
INFO: [SYN 201-210] Renamed object name 'convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s_line_buffer_2_2' to 'convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s_line_buffedEe' due to the length limit 80
INFO: [RTGEN 206-100] Generating core module 'CNN_add_31ns_31ns_31_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_32ns_32ns_32_1_1': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_5ns_5ns_5_1_1': 4 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_8ns_8ns_8_1_1': 10 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_9ns_9ns_9_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dadd_64ns_64ns_64_4_full_dsp_1': 10 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dcmp_64ns_64ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dmul_64ns_64ns_64_4_max_dsp_1': 9 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s'.
INFO: [HLS 200-111]  Elapsed time: 0.7 seconds; current allocated memory: 246.363 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s_line_buffer_1_4' to 'convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s_line_buffeeOg' due to the length limit 80
INFO: [SYN 201-210] Renamed object name 'convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s_line_buffer_0_4' to 'convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s_line_buffefYi' due to the length limit 80
INFO: [SYN 201-210] Renamed object name 'convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s_line_buffer_2_4' to 'convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s_line_buffeg8j' due to the length limit 80
INFO: [RTGEN 206-100] Generating core module 'CNN_add_11ns_11ns_11_1_1': 10 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_12ns_12ns_12_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_31ns_31ns_31_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_32ns_32ns_32_1_1': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_4ns_4ns_4_1_1': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_5ns_5ns_5_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_8ns_8ns_8_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_9ns_9ns_9_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dadd_64ns_64ns_64_4_full_dsp_1': 10 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dcmp_64ns_64ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dmul_64ns_64ns_64_4_max_dsp_1': 9 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s'.
INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 251.735 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'convolution_double_double_double_double_7_7_8_8_7_7_3_3_1_1_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'CNN_add_10ns_10ns_10_1_1': 11 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_31ns_31ns_31_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_32ns_32ns_32_1_1': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_3ns_3ns_3_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_4ns_4ns_4_1_1': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_6ns_6ns_6_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_8ns_8ns_8_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dadd_64ns_64ns_64_4_full_dsp_1': 10 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dcmp_64ns_64ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dmul_64ns_64ns_64_4_max_dsp_1': 9 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'convolution_double_double_double_double_7_7_8_8_7_7_3_3_1_1_s'.
INFO: [HLS 200-111]  Elapsed time: 0.43 seconds; current allocated memory: 257.462 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'convolution_double_double_double_double_4_4_8_8_4_4_3_3_1_1_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
WARNING: [RTGEN 206-101] Register 'line_buffer_1_10_0' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'line_buffer_1_10_1' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'line_buffer_1_10_2' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'line_buffer_1_10_3' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'line_buffer_2_10_0' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'line_buffer_2_10_1' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'line_buffer_2_10_2' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'line_buffer_2_10_3' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'line_buffer_0_10_0' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'line_buffer_0_10_1' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'line_buffer_0_10_2' is power-on initialization.
WARNING: [RTGEN 206-101] Register 'line_buffer_0_10_3' is power-on initialization.
INFO: [RTGEN 206-104] Estimated max fanout for 'convolution_double_double_double_double_4_4_8_8_4_4_3_3_1_1_s' is 8747 from HDL expression: (1'b0 == ap_block_pp1_stage0_11001)
INFO: [RTGEN 206-100] Generating core module 'CNN_add_10ns_10ns_10_1_1': 10 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_31ns_31ns_31_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_32ns_32ns_32_1_1': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_3ns_3ns_3_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_4ns_4ns_4_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_6ns_6ns_6_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_7ns_7ns_7_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_9ns_9ns_9_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dadd_64ns_64ns_64_4_full_dsp_1': 10 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dcmp_64ns_64ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dmul_64ns_64ns_64_4_max_dsp_1': 9 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_mux_42_64_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'convolution_double_double_double_double_4_4_8_8_4_4_3_3_1_1_s'.
INFO: [HLS 200-111]  Elapsed time: 0.5 seconds; current allocated memory: 263.244 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'convolution_double_double_double_double_8_8_8_8_8_8_3_3_1_1_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'CNN_add_10ns_10ns_10_1_1': 11 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_31ns_31ns_31_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_32ns_32ns_32_1_1': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_3ns_3ns_3_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_4ns_4ns_4_1_1': 4 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_6ns_6ns_6_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_8ns_8ns_8_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dadd_64ns_64ns_64_4_full_dsp_1': 10 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dcmp_64ns_64ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dmul_64ns_64ns_64_4_max_dsp_1': 9 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'convolution_double_double_double_double_8_8_8_8_8_8_3_3_1_1_s'.
INFO: [HLS 200-111]  Elapsed time: 0.49 seconds; current allocated memory: 269.262 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s_line_buffer_1_3' to 'convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s_line_buffehbi' due to the length limit 80
INFO: [SYN 201-210] Renamed object name 'convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s_line_buffer_0_3' to 'convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s_line_buffeibs' due to the length limit 80
INFO: [SYN 201-210] Renamed object name 'convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s_line_buffer_2_3' to 'convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s_line_buffejbC' due to the length limit 80
INFO: [RTGEN 206-100] Generating core module 'CNN_add_10ns_10ns_10_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_11ns_11ns_11_1_1': 8 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_12ns_12ns_12_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_31ns_31ns_31_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_32ns_32ns_32_1_1': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_4ns_4ns_4_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_5ns_5ns_5_1_1': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_6ns_6ns_6_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dadd_64ns_64ns_64_4_full_dsp_1': 10 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dcmp_64ns_64ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dmul_64ns_64ns_64_4_max_dsp_1': 9 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s'.
INFO: [HLS 200-111]  Elapsed time: 0.5 seconds; current allocated memory: 275.041 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'convolution_double_double_double_double_28_28_16_1_28_28_3_3_1_0_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'convolution_double_double_double_double_28_28_16_1_28_28_3_3_1_0_s_line_buffer_1_1' to 'convolution_double_double_double_double_28_28_16_1_28_28_3_3_1_0_s_line_buffekbM' due to the length limit 80
INFO: [SYN 201-210] Renamed object name 'convolution_double_double_double_double_28_28_16_1_28_28_3_3_1_0_s_line_buffer_0_1' to 'convolution_double_double_double_double_28_28_16_1_28_28_3_3_1_0_s_line_buffelbW' due to the length limit 80
INFO: [SYN 201-210] Renamed object name 'convolution_double_double_double_double_28_28_16_1_28_28_3_3_1_0_s_line_buffer_2_1' to 'convolution_double_double_double_double_28_28_16_1_28_28_3_3_1_0_s_line_buffemb6' due to the length limit 80
INFO: [RTGEN 206-100] Generating core module 'CNN_add_31ns_31ns_31_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_32ns_32ns_32_1_1': 3 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_5ns_5ns_5_1_1': 4 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_8ns_8ns_8_1_1': 10 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_9ns_9ns_9_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dadd_64ns_64ns_64_4_full_dsp_1': 10 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dcmp_64ns_64ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dmul_64ns_64ns_64_4_max_dsp_1': 9 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'convolution_double_double_double_double_28_28_16_1_28_28_3_3_1_0_s'.
INFO: [HLS 200-111]  Elapsed time: 0.51 seconds; current allocated memory: 280.600 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'CNN' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/padding' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/width' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/hight' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/image_r' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/output_conv1' to 'ap_ovld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/output_pooling1' to 'ap_ovld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/output_conv2' to 'ap_ovld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/output_pooling2' to 'ap_ovld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/output_conv3' to 'ap_ovld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/output_pooling3' to 'ap_ovld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/output_conv4' to 'ap_ovld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/output_upsampling1' to 'ap_ovld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/output_conv5' to 'ap_ovld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/output_upsampling2' to 'ap_ovld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/output_conv6' to 'ap_ovld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/output_upsampling3' to 'ap_ovld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'CNN/output_conv7' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on function 'CNN' to 'ap_ctrl_hs'.
INFO: [RTGEN 206-100] Generating core module 'CNN_add_31ns_31ns_31_1_1': 12 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_4ns_4ns_4_1_1': 5 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_add_5ns_5ns_5_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'CNN_dcmp_64ns_64ns_1_2_no_dsp_1': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'CNN'.
INFO: [HLS 200-111]  Elapsed time: 0.53 seconds; current allocated memory: 286.481 MB.
INFO: [RTMG 210-278] Implementing memory 'CNN_convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s_line_buffebkb_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'CNN_convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s_line_buffecud_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-279] Implementing memory 'CNN_convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s_bias_conv1_rom' using block ROMs.
INFO: [RTMG 210-279] Implementing memory 'CNN_convolution_double_double_double_double_28_28_1_16_28_28_3_3_1_1_s_kernel_conv1_rom' using block ROMs.
INFO: [RTMG 210-279] Implementing memory 'CNN_convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s_bias_conv2_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'CNN_convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s_line_buffeeOg_ram (RAM)' using distributed RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'CNN_convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s_line_buffefYi_ram (RAM)' using distributed RAMs with power-on initialization.
INFO: [RTMG 210-279] Implementing memory 'CNN_convolution_double_double_double_double_14_14_16_8_14_14_3_3_1_1_s_kernel_conv2_rom' using block ROMs.
INFO: [RTMG 210-279] Implementing memory 'CNN_convolution_double_double_double_double_7_7_8_8_7_7_3_3_1_1_s_bias_conv3_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'CNN_convolution_double_double_double_double_7_7_8_8_7_7_3_3_1_1_s_line_buffer_1_5_ram (RAM)' using distributed RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'CNN_convolution_double_double_double_double_7_7_8_8_7_7_3_3_1_1_s_line_buffer_0_5_ram (RAM)' using distributed RAMs with power-on initialization.
INFO: [RTMG 210-279] Implementing memory 'CNN_convolution_double_double_double_double_7_7_8_8_7_7_3_3_1_1_s_kernel_conv3_rom' using block ROMs.
INFO: [RTMG 210-279] Implementing memory 'CNN_convolution_double_double_double_double_4_4_8_8_4_4_3_3_1_1_s_bias_conv4_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'CNN_convolution_double_double_double_double_4_4_8_8_4_4_3_3_1_1_s_kernel_conv4_rom' using block ROMs.
INFO: [RTMG 210-279] Implementing memory 'CNN_convolution_double_double_double_double_8_8_8_8_8_8_3_3_1_1_s_bias_conv5_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'CNN_convolution_double_double_double_double_8_8_8_8_8_8_3_3_1_1_s_line_buffer_1_ram (RAM)' using distributed RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'CNN_convolution_double_double_double_double_8_8_8_8_8_8_3_3_1_1_s_line_buffer_0_ram (RAM)' using distributed RAMs with power-on initialization.
INFO: [RTMG 210-279] Implementing memory 'CNN_convolution_double_double_double_double_8_8_8_8_8_8_3_3_1_1_s_kernel_conv5_rom' using block ROMs.
INFO: [RTMG 210-279] Implementing memory 'CNN_convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s_bias_conv6_rom' using block ROMs.
INFO: [RTMG 210-278] Implementing memory 'CNN_convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s_line_buffehbi_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'CNN_convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s_line_buffeibs_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-279] Implementing memory 'CNN_convolution_double_double_double_double_16_16_8_16_14_14_3_3_1_0_s_kernel_conv6_rom' using block ROMs.
INFO: [RTMG 210-279] Implementing memory 'CNN_convolution_double_double_double_double_28_28_16_1_28_28_3_3_1_0_s_kernel_conv7_rom' using block ROMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:00:30 ; elapsed = 00:00:54 . Memory (MB): peak = 1021.656 ; gain = 650.949 ; free physical = 3155 ; free virtual = 30380
INFO: [VHDL 208-304] Generating VHDL RTL for CNN with prefix CNN_.
INFO: [VLOG 209-307] Generating Verilog RTL for CNN with prefix CNN_.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 222.07 MHz
INFO: [HLS 200-112] Total elapsed time: 54.33 seconds; peak allocated memory: 286.481 MB.
INFO: [Common 17-206] Exiting vitis_hls at Mon Jan 29 21:01:32 2024...
